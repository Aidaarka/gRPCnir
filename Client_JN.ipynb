{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba5f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69a17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import client\n",
    "import pandas as pd\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030833c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = client.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef9baf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset data.csv successfully uploaded!\n"
     ]
    }
   ],
   "source": [
    "p.upload_data('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82abe6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in column:  103273.0\n"
     ]
    }
   ],
   "source": [
    "p.max_by_column(\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4f404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of dataset: \n",
      "\n",
      " <class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6077 entries, 0 to 6076\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Carrier Code             6077 non-null   object \n",
      " 1   Flight Number            6077 non-null   int64  \n",
      " 2   Tail Number              6077 non-null   object \n",
      " 3   Origin Airport           6077 non-null   object \n",
      " 4   Scheduled Arrival Time   6077 non-null   object \n",
      " 5   Arrival Delay (Minutes)  6077 non-null   int64  \n",
      " 6   Wind                     6077 non-null   object \n",
      " 7   Temperature              6077 non-null   float64\n",
      " 8   Humidity                 6077 non-null   float64\n",
      " 9   Wind Speed               6077 non-null   float64\n",
      " 10  Pressure                 6077 non-null   float64\n",
      " 11  Condition                6077 non-null   object \n",
      "dtypes: float64(4), int64(2), object(6)\n",
      "memory usage: 569.8+ KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p.print_df_info(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0139e88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 rows of dataset: \n",
      "\n",
      "   Carrier Code  Flight Number Tail Number Origin Airport  \\\n",
      "0           CO          218.0      N46625            EWR   \n",
      "1           CO          793.0      N27610            IAH   \n",
      "2           CO         1006.0      N69311            IAH   \n",
      "\n",
      "  Scheduled Arrival Time  Arrival Delay (Minutes) Wind  Temperature  Humidity  \\\n",
      "0    2005-01-01 15:28:00                     -7.0  VAR         42.0      0.50   \n",
      "1    2005-01-01 12:13:00                     22.0    E         44.0      0.50   \n",
      "2    2005-01-01 13:58:00                      2.0  VAR         44.0      0.48   \n",
      "\n",
      "   Wind Speed   Pressure Condition  \n",
      "0       3.129  102528.08    Cloudy  \n",
      "1       4.023  102528.08    Cloudy  \n",
      "2       2.682  102494.22    Cloudy  \n"
     ]
    }
   ],
   "source": [
    "p.print_nrows_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177157aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/aidar/Desktop/SAS/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea38d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dmax = str(df['Pressure'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24883be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'103273.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1c7e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6077 entries, 0 to 6076\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Carrier Code             6077 non-null   object \n",
      " 1   Flight Number            6077 non-null   int64  \n",
      " 2   Tail Number              6077 non-null   object \n",
      " 3   Origin Airport           6077 non-null   object \n",
      " 4   Scheduled Arrival Time   6077 non-null   object \n",
      " 5   Arrival Delay (Minutes)  6077 non-null   int64  \n",
      " 6   Wind                     6077 non-null   object \n",
      " 7   Temperature              6077 non-null   float64\n",
      " 8   Humidity                 6077 non-null   float64\n",
      " 9   Wind Speed               6077 non-null   float64\n",
      " 10  Pressure                 6077 non-null   float64\n",
      " 11  Condition                6077 non-null   object \n",
      "dtypes: float64(4), int64(2), object(6)\n",
      "memory usage: 569.8+ KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "buf = io.StringIO()\n",
    "df.info(buf=buf)\n",
    "s = buf.getvalue()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6673299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/12 18:09:33 WARN Utils: Your hostname, aidar-HP-Pavilion resolves to a loopback address: 127.0.1.1; using 192.168.1.38 instead (on interface wlo1)\n",
      "22/06/12 18:09:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/12 18:09:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/12 18:09:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName('Test run for big DataFrame')\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf811d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path = f\"/home/aidar/Desktop/SAS/data.csv\"\n",
    "dfspark = spark.read.csv(path, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384dcccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Carrier Code: string (nullable = true)\n",
      " |-- Flight Number: string (nullable = true)\n",
      " |-- Tail Number: string (nullable = true)\n",
      " |-- Origin Airport: string (nullable = true)\n",
      " |-- Scheduled Arrival Time: string (nullable = true)\n",
      " |-- Arrival Delay (Minutes): string (nullable = true)\n",
      " |-- Wind: string (nullable = true)\n",
      " |-- Temperature: string (nullable = true)\n",
      " |-- Humidity: string (nullable = true)\n",
      " |-- Wind Speed: string (nullable = true)\n",
      " |-- Pressure: string (nullable = true)\n",
      " |-- Condition: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dfspark.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02fe88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
